{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Homework: Week 1 - The Overfitting Trap in Marketing ROI\n",
    "\n",
    "## Dataset:\n",
    "https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Advertising.csv\n",
    "\n",
    "## Part 1: The \"Simple\" Model (Baseline)\n",
    "1.   **Split Your Data:** Before you do anything else, split your data into a training set and a test set using train_test_split. (Use a test_size=0.3 and random_state=1). You will use the training set to fit all your models and the test set to evaluate them.\n",
    "\n",
    "2.   **Fit & Interpret:** Fit a simple LinearRegression using only the three original features (TV, Radio, Newspaper).\n",
    "\n",
    "3.   **Write Down Coefficients and Performance metrics:** Note the coefficients for TV, Radio, and Newspaper and its performance metrics on both train set and test set. This will be your baseline model.\n",
    "\n",
    "## Part 2: The \"Overly Complex\" Model (The Trap)\n",
    "\n",
    "1.   **Create Polynomial Features:** Use PolynomialFeatures (try degree=5) to create a new, high-dimensional training set. Make sure to fit_transform on your training data and only .transform your test data. This will create many new features (e.g., TV^2, Radio^3, TV * Radio). Make sure to fit_transform on your training data and only .transform your test data.\n",
    "2.   **Scale Your Features:** Use StandardScaler. fit_transform on the polynomial training data and just .transform on the polynomial test data. (This is critical for regularization to work).\n",
    "3. **Fit the Overfit Model:** Fit a LinearRegression on this new, scaled, polynomial training set.\n",
    "3.   **Check the Coefficients and Metrics:** Print the model.coef_ and calculate its performance metrics.\n",
    "\n",
    "### Question 1 (Observation):\n",
    "* What do you observe about the coefficients? Are they large or small? Do they make any intuitive sense? What does this tell you about the risk of this model? (Hint: They will likely be huge and non-sensical, a classic sign of overfitting).\n",
    "* Print the metrics for this complex model on the training set.\n",
    "* Print the R-squared score for this same model on the test set.\n",
    "* What do you observe? What does the difference between these two scores (and the baseline score from Part 1) tell you about this model? Is this a good model?\n",
    "\n",
    "## Part 3: The Regularization Fix (Ridge & Lasso)\n",
    "Now, let's fix the model from Part 2.\n",
    "1.   Fit Ridge: Fit a Ridge model on the same scaled, polynomial training data.\n",
    "2.   Fit Lasso: Fit a Lasso model on the same scaled, polynomial training data.\n",
    "\n",
    "### Question 2 (Analysis & Performance):\n",
    "* What do you observe about the coefficients from the two new models now? Are they still large or small? Make some comments about the changes.\n",
    "* Look at the coefficients from your Lasso model. How many features did it set to zero? What does this tell you about the 'true' drivers of sales?\"\n",
    "* What is the performance metrics for your Ridge model on the train set and test set?\n",
    "* What is the performance metrics for your Lasso model on the train set and test set?\n",
    "* How do these scores compare to the 'overfit' model's test score? What does this prove about the value of regularization?\n",
    "\n",
    "### Question 3 (The Verdict):\n",
    "In the end, after trying a simple model, an overfit complex model, and two regularized models, what is your final recommendation to the CMO? Which channels (TV, Radio, Newspaper) are the most reliable drivers of sales?"
   ],
   "id": "a4a95dac40554422"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Answer",
   "id": "da3db7afd2305330"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.0) Import and inspect data",
   "id": "fbb533a0f7002c5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T10:04:46.883364Z",
     "start_time": "2025-11-22T10:04:46.830391Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Advertising.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     TV  Radio  Newspaper  Sales\n",
      "0           1  230.1   37.8       69.2   22.1\n",
      "1           2   44.5   39.3       45.1   10.4\n",
      "2           3   17.2   45.9       69.3    9.3\n",
      "3           4  151.5   41.3       58.5   18.5\n",
      "4           5  180.8   10.8       58.4   12.9\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  200 non-null    int64  \n",
      " 1   TV          200 non-null    float64\n",
      " 2   Radio       200 non-null    float64\n",
      " 3   Newspaper   200 non-null    float64\n",
      " 4   Sales       200 non-null    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 7.9 KB\n",
      "None\n",
      "       Unnamed: 0          TV       Radio   Newspaper       Sales\n",
      "count  200.000000  200.000000  200.000000  200.000000  200.000000\n",
      "mean   100.500000  147.042500   23.264000   30.554000   14.022500\n",
      "std     57.879185   85.854236   14.846809   21.778621    5.217457\n",
      "min      1.000000    0.700000    0.000000    0.300000    1.600000\n",
      "25%     50.750000   74.375000    9.975000   12.750000   10.375000\n",
      "50%    100.500000  149.750000   22.900000   25.750000   12.900000\n",
      "75%    150.250000  218.825000   36.525000   45.100000   17.400000\n",
      "max    200.000000  296.400000   49.600000  114.000000   27.000000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1) Train test split",
   "id": "cd10243850fee219"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T10:11:48.316058Z",
     "start_time": "2025-11-22T10:11:48.303502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[\"TV\", \"Radio\", \"Newspaper\"]]\n",
    "y = df[\"Sales\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ],
   "id": "8c0ca73baf0a0717",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2) Fit OLS",
   "id": "3dd0b0aad3a2fc38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T10:12:45.105779Z",
     "start_time": "2025-11-22T10:12:45.088153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ],
   "id": "d0be179c6f0d7ab2",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
