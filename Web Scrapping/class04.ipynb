{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-01T08:19:58.555834Z",
     "start_time": "2025-12-01T08:19:57.721731Z"
    }
   },
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Constructing Bag of Words",
   "id": "a9bb5f5d248f38a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:19:00.655511Z",
     "start_time": "2025-12-01T08:19:00.615632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv = CountVectorizer()\n",
    "texts =[\"Hello, this is a python course\", \"Hi, my bike broke this tuesday\"]\n",
    "\n",
    "X = cv.fit_transform(texts)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=cv.get_feature_names_out())\n",
    "\n",
    "df"
   ],
   "id": "36458a1e9a4fa48d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   bike  broke  course  hello  hi  is  my  python  this  tuesday\n",
       "0     0      0       1      1   0   1   0       1     1        0\n",
       "1     1      1       0      0   1   0   1       0     1        1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike</th>\n",
       "      <th>broke</th>\n",
       "      <th>course</th>\n",
       "      <th>hello</th>\n",
       "      <th>hi</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "      <th>python</th>\n",
       "      <th>this</th>\n",
       "      <th>tuesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Constructing Bag of Words with stopwords and tokenizers",
   "id": "3909e05e41e9e761"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:20:18.634981Z",
     "start_time": "2025-12-01T08:20:18.595595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv = CountVectorizer(stop_words='english', tokenizer=word_tokenize)\n",
    "texts =[\"Hello, this is a python course\", \"Hi, my bike broke this tuesday\"]\n",
    "\n",
    "X = cv.fit_transform(texts)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=cv.get_feature_names_out())\n",
    "\n",
    "df"
   ],
   "id": "c5ff1998b0f96d53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   ,  bike  broke  course  hello  hi  python  tuesday\n",
       "0  1     0      0       1      1   0       1        0\n",
       "1  1     1      1       0      0   1       0        1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,</th>\n",
       "      <th>bike</th>\n",
       "      <th>broke</th>\n",
       "      <th>course</th>\n",
       "      <th>hello</th>\n",
       "      <th>hi</th>\n",
       "      <th>python</th>\n",
       "      <th>tuesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Computing Jaccard similarity between two different texts",
   "id": "23ed8562c947fdba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:30:55.879943Z",
     "start_time": "2025-12-01T08:30:17.864160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"/Users/eduardo/Downloads/all_ECB_speeches.csv\"\n",
    "\n",
    "df = pd.read_csv(path, sep=\"|\", ).dropna()\n",
    "\n",
    "text = df['contents'].tolist()\n",
    "\n",
    "X = cv.fit_transform(text)"
   ],
   "id": "5340f9d6673b91f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cosine similarity by hand",
   "id": "bf0bfc0c946444cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:31:25.552869Z",
     "start_time": "2025-12-01T08:31:25.539942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr1 = X[0].toarray().flatten()\n",
    "arr2 = X[1].toarray().flatten()\n",
    "\n",
    "numerator = np.sum(arr1 * arr2)\n",
    "denominator = np.sqrt(np.sum(arr1 ** 2)) * np.sqrt(np.sum(arr2 ** 2))\n",
    "print(numerator / denominator)"
   ],
   "id": "dbce90446837932c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cosine similarity using `cosine_similarity`package",
   "id": "f64abd53e8c7ec2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:31:26.840559Z",
     "start_time": "2025-12-01T08:31:26.833337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(cosine_similarity(X[0].toarray(), X[1].toarray()))"
   ],
   "id": "f4bb43302d86780b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8221334445162073\n",
      "[[0.82213344]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T08:33:31.248117Z",
     "start_time": "2025-12-01T08:33:31.243561Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "19248fd890647e53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 81111)\t4\n",
      "  (0, 73955)\t1\n",
      "  (0, 43727)\t2\n",
      "  (0, 25938)\t3\n",
      "  (0, 67500)\t1\n",
      "  (0, 58064)\t1\n",
      "  (0, 39918)\t4\n",
      "  (0, 298)\t152\n",
      "  (0, 32334)\t41\n",
      "  (0, 43333)\t3\n",
      "  (0, 95985)\t28\n",
      "  (0, 63298)\t3\n",
      "  (0, 5231)\t8\n",
      "  (0, 67293)\t1\n",
      "  (0, 583)\t113\n",
      "  (0, 55137)\t3\n",
      "  (0, 85131)\t1\n",
      "  (0, 43933)\t2\n",
      "  (0, 79785)\t1\n",
      "  (0, 65684)\t4\n",
      "  (0, 9696)\t10\n",
      "  (0, 19972)\t1\n",
      "  (0, 76665)\t15\n",
      "  (0, 31067)\t1\n",
      "  (0, 21402)\t1\n",
      "  :\t:\n",
      "  (0, 19114)\t2\n",
      "  (0, 57180)\t1\n",
      "  (0, 75739)\t1\n",
      "  (0, 31147)\t1\n",
      "  (0, 76699)\t1\n",
      "  (0, 79704)\t1\n",
      "  (0, 8807)\t1\n",
      "  (0, 12773)\t1\n",
      "  (0, 48173)\t1\n",
      "  (0, 6200)\t1\n",
      "  (0, 79374)\t1\n",
      "  (0, 40010)\t1\n",
      "  (0, 81079)\t1\n",
      "  (0, 75789)\t1\n",
      "  (0, 47178)\t1\n",
      "  (0, 28748)\t1\n",
      "  (0, 29861)\t1\n",
      "  (0, 85856)\t1\n",
      "  (0, 45548)\t1\n",
      "  (0, 67269)\t1\n",
      "  (0, 81115)\t1\n",
      "  (0, 74775)\t1\n",
      "  (0, 13873)\t1\n",
      "  (0, 74118)\t1\n",
      "  (0, 56975)\t1\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
